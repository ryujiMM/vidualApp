{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f2d6f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-cognitiveservices-vision-computervision\n",
      "  Downloading azure_cognitiveservices_vision_computervision-0.9.0-py2.py3-none-any.whl (39 kB)\n",
      "Collecting msrest>=0.5.0\n",
      "  Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
      "     |████████████████████████████████| 85 kB 3.9 MB/s             \n",
      "\u001b[?25hCollecting azure-common~=1.1\n",
      "  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "     |████████████████████████████████| 41 kB 1.2 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: requests~=2.16 in /Users/maedaryuji/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2.26.0)\n",
      "Collecting azure-core>=1.24.0\n",
      "  Downloading azure_core-1.24.2-py3-none-any.whl (178 kB)\n",
      "     |████████████████████████████████| 178 kB 6.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /Users/maedaryuji/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2021.5.30)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: six>=1.11.0 in /Users/maedaryuji/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from azure-core>=1.24.0->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in /Users/maedaryuji/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from azure-core>=1.24.0->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (4.1.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/maedaryuji/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2.0.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/maedaryuji/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.26.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/maedaryuji/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (3.2)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     |████████████████████████████████| 151 kB 6.5 MB/s            \n",
      "\u001b[?25hInstalling collected packages: oauthlib, requests-oauthlib, isodate, azure-core, msrest, azure-common, azure-cognitiveservices-vision-computervision\n",
      "Successfully installed azure-cognitiveservices-vision-computervision-0.9.0 azure-common-1.1.28 azure-core-1.24.2 isodate-0.6.1 msrest-0.7.1 oauthlib-3.2.2 requests-oauthlib-1.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install azure-cognitiveservices-vision-computervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d16e1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /Users/maedaryuji/.pyenv/versions/3.6.5/lib/python3.6/site-packages (8.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "862a8f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "import json\n",
    "from array import array\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48e17bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('secret.json') as f:\n",
    "    secret =  json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02d4cd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = secret['KEY']\n",
    "ENDPOINT = secret['ENDPOINT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bf504f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# endpoint = os.environ['ENDPOINT']\n",
    "# key = os.environ['KEY']\n",
    "\n",
    "credentials = CognitiveServicesCredentials(KEY)\n",
    "client = ComputerVisionClient(\n",
    "    endpoint=ENDPOINT,\n",
    "    credentials=credentials\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3555110",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = \"landmarks\"\n",
    "url = \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQvk0dHg3_W5kx8W6MyMFCvi_W6EWVf7qftUCttKGfSs_DClGVV7SBlGxkbCK5FoxQ0-R0&usqp=CAU\"\n",
    "language = \"en\"\n",
    "max_descriptions = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e5cd7c",
   "metadata": {},
   "source": [
    "## captionの取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d9e9caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'a beach with a large body of water and a land with a structure in the distance' with confdence 39.90%\n"
     ]
    }
   ],
   "source": [
    "analysis = client.describe_image(url, max_descriptions, language)\n",
    "\n",
    "if (len(analysis.captions) == 0):\n",
    "    print('No description detected.')\n",
    "else:\n",
    "    for caption in analysis.captions:\n",
    "        print(\"'{}' with confdence {:.2f}%\".format(caption.text, caption.confidence*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10f1166",
   "metadata": {},
   "source": [
    "## 画像カテゴリの取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f579826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Categorize an image - remote =====\n",
      "Categories from remote image: \n",
      "'outdoor_oceanbeach' with confidence 50.78%\n",
      "'sky_cloud' with confidence 42.58%\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Categorize an image - remote =====\")\n",
    "remote_image_features = [\"categories\"]\n",
    "categorize_results_remote = client.analyze_image(url , remote_image_features)\n",
    "\n",
    "print(\"Categories from remote image: \")\n",
    "if (len(categorize_results_remote.categories) == 0):\n",
    "    print(\"No categories detected.\")\n",
    "else:\n",
    "    for category in categorize_results_remote.categories:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(category.name, category.score * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fd9f8f",
   "metadata": {},
   "source": [
    "## 画像タグの取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a6d5eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Tag an image - remote =====\n",
      "Tags in the remote image: \n",
      "'outdoor' with confidence 99.53%\n",
      "'cloud' with confidence 99.49%\n",
      "'sky' with confidence 99.43%\n",
      "'nature' with confidence 99.18%\n",
      "'water' with confidence 96.69%\n",
      "'coastal and oceanic landforms' with confidence 95.96%\n",
      "'beach' with confidence 95.74%\n",
      "'landscape' with confidence 95.08%\n",
      "'coast' with confidence 95.05%\n",
      "'tropics' with confidence 94.39%\n",
      "'aqua' with confidence 94.18%\n",
      "'azure' with confidence 92.68%\n",
      "'caribbean' with confidence 91.97%\n",
      "'shoal' with confidence 91.12%\n",
      "'sea' with confidence 91.10%\n",
      "'shore' with confidence 90.07%\n",
      "'bay' with confidence 89.26%\n",
      "'cay' with confidence 89.24%\n",
      "'body of water' with confidence 89.18%\n",
      "'ground' with confidence 87.26%\n",
      "'island' with confidence 86.94%\n",
      "'horizon' with confidence 86.07%\n",
      "'ocean' with confidence 74.46%\n",
      "'sand' with confidence 55.43%\n",
      "\n",
      "End of Computer Vision quickstart.\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Tag an image - remote =====\")\n",
    "# Call API with remote image\n",
    "tags_result_remote = client.tag_image(url )\n",
    "\n",
    "# Print results with confidence score\n",
    "print(\"Tags in the remote image: \")\n",
    "if (len(tags_result_remote.tags) == 0):\n",
    "    print(\"No tags detected.\")\n",
    "else:\n",
    "    for tag in tags_result_remote.tags:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(tag.name, tag.confidence * 100))\n",
    "print()\n",
    "'''\n",
    "END - Tag an Image - remote\n",
    "'''\n",
    "print(\"End of Computer Vision quickstart.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc0ad68",
   "metadata": {},
   "source": [
    "## 物体を検出する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4f1a93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Detect Objects - remote =====\n",
      "Detecting objects in remote image:\n",
      "object at location 213, 365, 85, 208\n",
      "object at location 218, 402, 179, 384\n",
      "object at location 238, 417, 298, 416\n",
      "object at location 116, 419, 60, 386\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Detect Objects - remote =====\")\n",
    "remote_image_url_objects = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/objects.jpg\"\n",
    "detect_objects_results_remote = client.detect_objects(remote_image_url_objects)\n",
    "\n",
    "print(\"Detecting objects in remote image:\")\n",
    "if len(detect_objects_results_remote.objects) == 0:\n",
    "    print(\"No objects detected.\")\n",
    "else:\n",
    "    for object in detect_objects_results_remote.objects:\n",
    "        print(\"object at location {}, {}, {}, {}\".format( \\\n",
    "        object.rectangle.x, object.rectangle.x + object.rectangle.w, \\\n",
    "        object.rectangle.y, object.rectangle.y + object.rectangle.h))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ace8035",
   "metadata": {},
   "source": [
    "## ローカルファイルに対応させる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "978c58bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Detect Objects - remote =====\n",
      "Detecting objects in remote image:\n",
      "object at location 879, 1201, 262, 773\n",
      "object at location 426, 1085, 835, 1271\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Detect Objects - remote =====\")\n",
    "\n",
    "# Open local image file\n",
    "local_image_path = os.path.join ( \"sample01.jpg\")\n",
    "local_image = open(local_image_path, \"rb\")\n",
    "\n",
    "detect_objects_results_remote = client.detect_objects_in_stream(local_image)\n",
    "\n",
    "print(\"Detecting objects in remote image:\")\n",
    "if len(detect_objects_results_remote.objects) == 0:\n",
    "    print(\"No objects detected.\")\n",
    "else:\n",
    "    for object in detect_objects_results_remote.objects:\n",
    "        print(\"object at location {}, {}, {}, {}\".format( \\\n",
    "        object.rectangle.x, object.rectangle.x + object.rectangle.w, \\\n",
    "        object.rectangle.y, object.rectangle.y + object.rectangle.h))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b69460d",
   "metadata": {},
   "source": [
    "## 関数化させる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "49b88f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags(filepath):\n",
    "    local_image = open(filepath, \"rb\")\n",
    "\n",
    "    tags_result = client.tag_image_in_stream(local_image)\n",
    "    tags = tags_result.tags\n",
    "    tags_name = []\n",
    "    for tag in tags:\n",
    "        tags_name.append(tag.name)\n",
    "\n",
    "    return tags_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e5f8fe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_image_path =  \"sample01.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7e5312e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tableware',\n",
       " 'food',\n",
       " 'baked goods',\n",
       " 'plate',\n",
       " 'drink',\n",
       " 'coffee cup',\n",
       " 'dishware',\n",
       " 'saucer',\n",
       " 'snack',\n",
       " 'serveware',\n",
       " 'meal',\n",
       " 'mug',\n",
       " 'tea',\n",
       " 'fast food',\n",
       " 'breakfast',\n",
       " 'fork',\n",
       " 'kitchen utensil',\n",
       " 'dish',\n",
       " 'brunch',\n",
       " 'platter',\n",
       " 'dessert',\n",
       " 'cup',\n",
       " 'coffee',\n",
       " 'indoor',\n",
       " 'sitting',\n",
       " 'table']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tags(local_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5c42a13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(filepath):\n",
    "    local_image = open(filepath, \"rb\")\n",
    "    detect_objects_results= client.detect_objects_in_stream(local_image)\n",
    "\n",
    "    print(\"Detecting objects in remote image:\")\n",
    "    if len(detect_objects_results.objects) == 0:\n",
    "        print(\"No objects detected.\")\n",
    "    else:\n",
    "        for object in detect_objects_results.objects:\n",
    "            print(\"object at location {}, {}, {}, {}\".format( \\\n",
    "            object.rectangle.x, object.rectangle.x + object.rectangle.w, \\\n",
    "            object.rectangle.y, object.rectangle.y + object.rectangle.h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6702f36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_image_path =  \"sample01.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "45d2b3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting objects in remote image:\n",
      "object at location 879, 1201, 262, 773\n",
      "object at location 426, 1085, 835, 1271\n"
     ]
    }
   ],
   "source": [
    "detect_objects(local_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e63a86d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
